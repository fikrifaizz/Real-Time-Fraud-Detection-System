{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fikrifaizz/Real-Time-Fraud-Detection-System/blob/main/notebooks/02_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DYKtbOUo-unl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: 590,540 rows, 424 columns\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
        "print(f\"Loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Time Features...\n",
            "Created 5 time features\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Time Features...\")\n",
        "\n",
        "# Basic time features\n",
        "df['hour'] = (df['TransactionDT'] % (24*3600)) // 3600\n",
        "df['day'] = df['TransactionDT'] // (24*3600)\n",
        "df['day_of_week'] = df['day'] % 7\n",
        "\n",
        "# Time buckets\n",
        "df['is_night'] = ((df['hour'] >= 0) & (df['hour'] < 6)).astype(int)\n",
        "df['is_weekend'] = (df['day_of_week'].isin([5, 6])).astype(int)\n",
        "\n",
        "print(f\"Created 5 time features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Amount Features...\n",
            "Created 3 amount features\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Amount Features...\")\n",
        "\n",
        "# Amount statistics\n",
        "df['amount_log'] = np.log1p(df['TransactionAmt'])\n",
        "df['amount_decimal'] = df['TransactionAmt'] - df['TransactionAmt'].astype(int)\n",
        "\n",
        "# Round numbers (fraud often uses round numbers)\n",
        "df['is_round_amount'] = (df['TransactionAmt'] % 10 == 0).astype(int)\n",
        "\n",
        "print(f\"Created 3 amount features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Card Aggregation Features...\n",
            "Created 6 card aggregation features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1d/rtg1b32x7sg4fj4dmx9191l40000gn/T/ipykernel_63599/3093807594.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['card_txn_std'].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Card Aggregation Features...\")\n",
        "\n",
        "# Group by card1 (main card identifier)\n",
        "card_agg = df.groupby('card1').agg({\n",
        "    'TransactionAmt': ['count', 'mean', 'std', 'min', 'max'],\n",
        "    'TransactionDT': lambda x: x.max() - x.min()  # card usage duration\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "card_agg.columns = ['card1', 'card_txn_count', 'card_txn_mean', \n",
        "                    'card_txn_std', 'card_txn_min', 'card_txn_max',\n",
        "                    'card_usage_duration']\n",
        "\n",
        "# Merge back\n",
        "df = df.merge(card_agg, on='card1', how='left')\n",
        "\n",
        "# Fill NaN in std (happens when count=1)\n",
        "df['card_txn_std'].fillna(0, inplace=True)\n",
        "\n",
        "print(f\"Created 6 card aggregation features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Email Domain Features...\n",
            "Created 4 email features\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Email Domain Features...\")\n",
        "\n",
        "# Email domain counts\n",
        "for email_col in ['P_emaildomain', 'R_emaildomain']:\n",
        "    if email_col in df.columns:\n",
        "        email_counts = df[email_col].value_counts().to_dict()\n",
        "        df[f'{email_col}_count'] = df[email_col].map(email_counts)\n",
        "        \n",
        "        # Popular email flag\n",
        "        top_emails = df[email_col].value_counts().head(10).index.tolist()\n",
        "        df[f'{email_col}_is_popular'] = df[email_col].isin(top_emails).astype(int)\n",
        "\n",
        "print(f\"Created 4 email features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Device Features...\n",
            "Created device features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1d/rtg1b32x7sg4fj4dmx9191l40000gn/T/ipykernel_63599/3308541218.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['device_usage_count'].fillna(0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Device Features...\")\n",
        "\n",
        "# Device type consistency\n",
        "if 'DeviceType' in df.columns and 'DeviceInfo' in df.columns:\n",
        "    # Device usage count\n",
        "    device_counts = df['DeviceInfo'].value_counts().to_dict()\n",
        "    df['device_usage_count'] = df['DeviceInfo'].map(device_counts)\n",
        "    df['device_usage_count'].fillna(0, inplace=True)\n",
        "\n",
        "print(f\"Created device features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Address Match Features...\n",
            "Created address match feature\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Address Match Features...\")\n",
        "\n",
        "# Check if purchaser and recipient addresses match\n",
        "if 'addr1' in df.columns and 'addr2' in df.columns:\n",
        "    df['addr_match'] = (df['addr1'] == df['addr2']).astype(int)\n",
        "\n",
        "print(f\"Created address match feature\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Velocity Features...\n",
            "Created 2 velocity features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/1d/rtg1b32x7sg4fj4dmx9191l40000gn/T/ipykernel_63599/275829149.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['time_since_last_txn'].fillna(df['time_since_last_txn'].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Velocity Features...\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values('TransactionDT').reset_index(drop=True)\n",
        "\n",
        "# Card velocity: time since last transaction\n",
        "df['time_since_last_txn'] = df.groupby('card1')['TransactionDT'].diff()\n",
        "df['time_since_last_txn'].fillna(df['time_since_last_txn'].median(), inplace=True)\n",
        "\n",
        "# Fast transactions flag (< 1 hour)\n",
        "df['is_fast_transaction'] = (df['time_since_last_txn'] < 3600).astype(int)\n",
        "\n",
        "print(f\"Created 2 velocity features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating Missing Indicators...\n",
            "Created missing indicators\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCreating Missing Indicators...\")\n",
        "\n",
        "# Identity missing flag\n",
        "identity_cols = [col for col in df.columns if col.startswith('id_')]\n",
        "if identity_cols:\n",
        "    df['identity_missing_count'] = df[identity_cols].isnull().sum(axis=1)\n",
        "    df['has_identity_info'] = (df['identity_missing_count'] < len(identity_cols)).astype(int)\n",
        "\n",
        "print(f\"Created missing indicators\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Encoding Categorical Features...\n",
            "Encoded 29 categorical features\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEncoding Categorical Features...\")\n",
        "\n",
        "# Select categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "cat_cols = [col for col in cat_cols if col not in ['TransactionID']]\n",
        "\n",
        "# Label encode\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "print(f\"Encoded {len(cat_cols)} categorical features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving Featured Data...\n",
            "Saved: ../data/processed/featured_data.csv\n",
            "   Shape: (590540, 446)\n",
            "   Memory: 2009.4 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSaving Featured Data...\")\n",
        "\n",
        "df.to_csv('../data/processed/featured_data.csv', index=False)\n",
        "print(f\"Saved: ../data/processed/featured_data.csv\")\n",
        "print(f\"   Shape: {df.shape}\")\n",
        "print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPLITTING DATA (Time-Based)\n",
            "\n",
            "Split Complete:\n",
            "   Train: 354,324 rows (60.0%)\n",
            "   Val:   118,108 rows (20.0%)\n",
            "   Test:  118,108 rows (20.0%)\n",
            "\n",
            "Fraud Distribution:\n",
            "   Train: 3.38%\n",
            "   Val:   3.90%\n",
            "   Test:  3.44%\n",
            "\n",
            "Saved all splits to data/processed/\n"
          ]
        }
      ],
      "source": [
        "print(\"SPLITTING DATA (Time-Based)\")\n",
        "\n",
        "df = df.sort_values('TransactionDT').reset_index(drop=True)\n",
        "\n",
        "# Calculate split indices\n",
        "n = len(df)\n",
        "train_end = int(n * 0.6)\n",
        "val_end = int(n * 0.8)\n",
        "\n",
        "# Split\n",
        "train_df = df.iloc[:train_end].copy()\n",
        "val_df = df.iloc[train_end:val_end].copy()\n",
        "test_df = df.iloc[val_end:].copy()\n",
        "\n",
        "print(f\"\\nSplit Complete:\")\n",
        "print(f\"   Train: {len(train_df):,} rows ({len(train_df)/n*100:.1f}%)\")\n",
        "print(f\"   Val:   {len(val_df):,} rows ({len(val_df)/n*100:.1f}%)\")\n",
        "print(f\"   Test:  {len(test_df):,} rows ({len(test_df)/n*100:.1f}%)\")\n",
        "\n",
        "# Check fraud distribution\n",
        "print(f\"\\nFraud Distribution:\")\n",
        "print(f\"   Train: {train_df['isFraud'].mean()*100:.2f}%\")\n",
        "print(f\"   Val:   {val_df['isFraud'].mean()*100:.2f}%\")\n",
        "print(f\"   Test:  {test_df['isFraud'].mean()*100:.2f}%\")\n",
        "\n",
        "# Save splits\n",
        "train_df.to_csv('../data/processed/train_set.csv', index=False)\n",
        "val_df.to_csv('../data/processed/val_set.csv', index=False)\n",
        "test_df.to_csv('../data/processed/test_set.csv', index=False)\n",
        "\n",
        "print(f\"\\nSaved all splits to data/processed/\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP6AIgoKSjNPZDXHk2hngzo",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
